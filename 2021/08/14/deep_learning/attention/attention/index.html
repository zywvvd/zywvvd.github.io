

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>
<script type="text/javascript" src="/js/jquery.js"></script>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="
随着神经网络的发展，注意力模型已经被广泛的应用到自然语言处理，统计学习语音识别和计算机视觉等人工智能相关领域。
">
  <meta name="author" content="Yiwei Zhang">
  <meta name="keywords" content="人工智能, 深度学习, 个人博客, 机器学习">
  
  <title>神经网络 Attention - 又见苍岚</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"www.zywvvd.com","root":"/","version":"1.8.11","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="又见苍岚" type="application/atom+xml">
</head>


<body>

  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Fluid</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

		<div class="banner" id="banner" parallax=true
			 style="background: url('https://photos.zywvvd.com/vvd-dell-2021-win-10/20210812235004.jpg') no-repeat center center;
			   background-size: cover;">

      <div class="full-bg-img" >

		
		<div id="banner_video_insert">
		</div>
		<script>
						
			var ua = navigator.userAgent;
			var ipad = ua.match(/(iPad).*OS\s([\d_]+)/),
				isIphone = !ipad && ua.match(/(iPhone\sOS)\s([\d_]+)/),
				isAndroid = ua.match(/(Android)\s+([\d.]+)/),
				isMobile = isIphone || isAndroid;

			function set_video_attr(id){
				
				var height = document.body.children[0].clientHeight

				var width = document.body.children[0].clientWidth

				var video_item = document.getElementById(id);

				if (height / width < 0.56){
					video_item.setAttribute('width', '100%');
					video_item.setAttribute('height', 'auto');
				} else {
					video_item.setAttribute('height', '100%');
					video_item.setAttribute('width', 'auto');
				}
			}

			$.getJSON('/js/video_url.json', function(data){
				if (!isMobile){
					var video_list_length = data.length
					var seed = Math.random()
					index = Math.floor(seed * video_list_length)
					
					video_url = data[index]
					video_html_res = "<video id='video_item' style='position: absolute;' muted='muted' src=" + video_url + " autoplay='autoplay' loop='loop'></video>"

					document.getElementById("banner_video_insert").innerHTML = video_html_res;
					set_video_attr('video_item')
				}

			});

			if (!isMobile){
				window.onresize = function(){
					set_video_attr('video_item')
					}
				}
			</script>

		

        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="神经网络 Attention">
              
            </span>

            
              <div class="mt-3">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-author" aria-hidden="true"></i>
      Yiwei Zhang
    </span>
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2021-08-14 14:01" pubdate>
        2021年8月14日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      3.2k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      36
       分钟
    </span>
  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">神经网络 Attention</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：2021年8月20日 凌晨
                
              </p>
            
            <div class="markdown-body">
              <blockquote>
<p>随着神经网络的发展，注意力模型已经被广泛的应用到自然语言处理，统计学习语音识别和计算机视觉等人工智能相关领域。</p>
</blockquote>
<span id="more"></span>

<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Attention机制：又称为注意力机制，顾名思义，是一种能让模型对重要信息重点关注并充分学习吸收的技术.通俗的讲就是把注意力集中放在重要的点上，而忽略其他不重要的因素。其中重要程度的判断取决于应用场景，根据应用场景的不同，Attention分为<strong>空间注意力</strong>和<strong>时间注意力</strong>，前者用于<strong>图像处理</strong>，后者用于<strong>自然语言处理.</strong></p>
<p>注意力机制的灵感来源可以归结到人对环境的生理感知上来。比方说，我们的视觉系统更倾向于去挑选影像中的部分信息进行集中分析而忽略掉图像中的无关信息。与此类似，很多设计到语言，语音和视觉的问题中都包含与研究任务密切相关的信息，同时也包含着一些无关的信息。比方说，在文本翻译和总结任务中，可能只有输入序列的某些单词与我们的下一个预测输出值有关；在图像标注任务中，可能某些局部信息与下一个标注单词联系更为密切。注意力机制将这种相关系进行了整合，允许模型动态地去关注输入的特定部分从而更为有效地完成手头的任务。</p>
<p>在神经网络结构中加入注意力模型主要是基于三点考虑：</p>
<ol>
<li>首先是这些模型在众多的任务中取得了非常好的性能，比方说机器翻译、问答系统、情感分析、词性标注选民分析和问答系统。</li>
<li>在提升模型性能的同时，注意力机制增加了神经网络结构的可解释性。由于传统的神经网络是一个黑盒模型，因此提高其可解释性对机器学习模型的公平性、可靠性和透明性的提高至关重要。</li>
<li>能够帮助缓解递归神经网络中的一些缺陷，比方说随着输入序列长度的增加导致的性能下降和对输入的顺序处理所导致的计算效率低下。本文的目的在于对注意力模型进行一个简单且易理解的介绍。</li>
</ol>
<h3 id="传统编码的弊端"><a href="#传统编码的弊端" class="headerlink" title="传统编码的弊端"></a>传统编码的弊端</h3><p>注意力机制最早用在 seq2seq 模型上<strong>，</strong>原始编解码模型的encode过程会生成一个中间向量C，用于保存原序列的语义信息。但是这个向量长度是固定的，<strong>当输入原序列的长度比较长时，向量C无法保存全部的语义信息</strong>，上下文语义信息受到了限制，这也限制了模型的理解能力。</p>
<p>常规的编码方法，<strong>无法体现对一个句子序列中不同语素的关注程度</strong>，在自然语言中，一个句子中的不同部分是有不同含义和重要性的，比如：I hate this movie。 如果是做情感分析的应用场景，训练的时候明显应该对hate这个词语做更多的关注。</p>
<h3 id="注意力模型"><a href="#注意力模型" class="headerlink" title="注意力模型"></a>注意力模型</h3><p>一个经典的序列模型 (sequence-to-sequence) 包含一个编码部分和一个解码部分。编码器通常采用一个循环神经网络结构来对序列的输入${x _ { 1 }, x _ { 2 }, \cdots , x _ { T } }$​​​​​​​​​  进行编码得到一组固定长度的编码向量 $ {h_ { 1}, h_ { 2}, \cdots, h_ { T } } $​​。解码器同样利用一个RNN结构读取单个输入 $ h_{T} $​​组固定长度的编码向量 $ {h_ {  1 }, h _ { 2 }, \cdots , h _ { T } } $​​ 。解码器同样利用一个RNN结构读取单个输入 $ h_{T} $​​ 然后一个接一个的进行输出得到一个输出序列 $  {x_ {1 }, x_{2 }, \cdots, x_{T ^ { \prime}} } $​​ 。其中 $ T $​​ 和 $ T^{\prime} $​​ 分别代表输入和输出序列的长度。在每个位置$ t, h_{t} $​​ 和 $ s_{t} $​​​​​​​​​分别代表该位置编码器和解码器的隐藏状态。</p>
<p><img src="https://photos.zywvvd.com/vvd-dell-2021-win-10/20210816234637.png" srcset="/img/loading.gif" lazyload alt="编码器-解码器结构:(a)传统结构 (b)加入注意力机制的模型的结构"></p>
<h3 id="核心思路"><a href="#核心思路" class="headerlink" title="核心思路"></a>核心思路</h3><p>注意力模型通过允许解码器访问所有编码器产生的输出 $ {h_{1}, h_{2}, \cdots, h_ { T}} $​​ 来克服传统结构的缺点。其核心思想是对编码器的所有输出进行加权组合后输入到当前位置的解码器中来影响解码器的输出。通过对编码器的输出进行加权，在实现输入与输出的对齐的同时还能够利用更多的原始数据的上下文信息。</p>
<h4 id="注意力机制的引入"><a href="#注意力机制的引入" class="headerlink" title="注意力机制的引入"></a>注意力机制的引入</h4><p>引入注意力机制的模型的结构如图2(b)所示。注意力模块能够自动地学习权重 $ \alpha_{i j} $ 用来捕捉编码器隐藏状态$ h_{i} $和解码器隐藏状态$ s_{j} $ 的相关性。习得的这些注意力权重将会被用来构建一个上下文向量 $ c $ 来作为解码器的输入。在解码器的每个位置 $ j $,上下文向量 $ c_{j} $ 是由注意力权重对所有的编码器的隐藏状态进行加权求和进行得到的，即: $ c_{j}=\sum_{i=1}^{T^{\prime}} \alpha_{i j} h_{i} $ 。于是, 这一上下文向量其实为解码器提供了一种访问整个输入序列并且关注序列中的特定相关位置的一种机制，我们称这 种机制为注意力机制。</p>
<h4 id="注意力权重的学习"><a href="#注意力权重的学习" class="headerlink" title="注意力权重的学习"></a>注意力权重的学习</h4><p>注意力权重的学习是通过在原始的网络结构中增加一个前馈网络来实现的。这一前馈网络的注意力权重的值$ \alpha_{i j} $是编码器隐藏状态值 $ h_{j} $和解码器内部隐藏状态值$ \boldsymbol{S}_{i-1} $的函数。该前馈网络可以与之前的网络结构一起进行训练。</p>
<p>该权重值可以通过下面的表达式算出:</p>

$$
\begin{aligned}
e_{i j} &=v_{a}^{T} \tanh \left(W_{a} s_{i-1}+U_{a} h_{j}\right) \\
\alpha_{i j} &=\frac{\exp \left(e_{i j}\right)}{\sum_{k=1} T_{x} \exp \left(e_{i k}\right)}
\end{aligned}
$$


<p>其中 $ v_{a}, W_{a}, U_{a} $​ 是注意力网络的权重值。</p>
<h3 id="注意力机制的可解释性"><a href="#注意力机制的可解释性" class="headerlink" title="注意力机制的可解释性"></a>注意力机制的可解释性</h3><p>人们对人工智能模型的可解释性有着巨大的兴趣，这是由模型的性能、透明度和公平性驱动的。然而，神经网络，尤其是深度学习结构因其不可预测性而受到批评。从可解释性的角度来看，注意力模型特别有趣，因为它允许我们直接检查深度学习体系结构的内部工作。针对输入和输出均为一个序列的问题，注意力模型的一个重要假设是学习得到的注意力权重体现了当前需输出的数据与输入序列的某些特定位置数据的相关性。为了验证这一假设，我们可以通过对一组输入输出序列对进行可视化。</p>
<p>研究人员将注意力权重可视化，尽管不同语言的主语-动名词位置不同，但法语和英语的句子自动对齐的效果很明显。在一般情况下，注意模型通过正确地将海洋环境与海洋环境进行比对，显示出非单调的一致性。</p>
<p><img src="https://photos.zywvvd.com/vvd-dell-2021-win-10/20210818001633.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><h4 id="基本流程描述"><a href="#基本流程描述" class="headerlink" title="基本流程描述"></a>基本流程描述</h4><p>以 seq2seq 模型为例子，对于一个句子序列S，其由单词序列$[w_1,w_2,w_3,…,w_n]$​构成：</p>
<ol>
<li>将S的每个单词 $ w_{i} $ 编码为一个单独向量 $ v_{i} $​, 这里对应seq2seq模型, 就是在encoder编码阶段，每个时间步单位(即每个单词)的输出隐状态。</li>
<li>在解码decoder阶段，待预测词的输入隐状态C(即上一个时间步的输出状态)与 (1) 中每个单词的隐状态相乘再做 softmax 归一化后得到权重分数，使用学习到的注意力权重 $ a_{i} $ 对 (1) 中得到的所有单词向量做加权线性组合 $ Z=\sum_{i} a_{i} v_{i} $​。</li>
<li>利于输入状态C以及输入变量Z作为对待预测词的共同输入，来进行预测。</li>
</ol>
<p>我们的最终目标是要能够帮助decoder在生成词语时，有一个不同词语的权重的参考。在训练时，对于decoder我们是有训练目标的，此时将decoder中的信息定义为一个<strong>Query。</strong>而encoder中包含了所有可能出现的词语，我们将其作为一个<strong>字典</strong>，该字典的<strong>key</strong>为所有encoder的序列信息。n个单词相当于当前字典中有n条记录，而字典的<strong>value</strong>通常也是所有encoder的序列信息。</p>
<p>上面对应于第一步，然后是第二部计算注意力权重，由于我们要让模型自己去学习该对哪些语素重点关注，因此要用我们的学习目标Query来参与这个过程，因此对于Query的每个向量，通过一个函数 $ a_{i}=F\left(Q_{i}, K\right) $，计算预测i时刻词时，需要学习的注意力权重，由于包含n个单词，因此， $a_i$ 应当是一个n维的向量，为了后续计算方便，需要将该向量进行softmax归一化，让向量的每一维元素都是一个概率值。</p>
<p><img src="https://photos.zywvvd.com/vvd-dell-2021-win-10/20210819232635.png" srcset="/img/loading.gif" lazyload></p>
<p>最后对Value vectors进行加权线性组合，得到带权重参考的“字典”输出：</p>
<p><img src="https://photos.zywvvd.com/vvd-dell-2021-win-10/20210819232741.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="公式步骤"><a href="#公式步骤" class="headerlink" title="公式步骤"></a>公式步骤</h4><ol>
<li>首先利用 RNN 模型已经得到了序列的隐层状态$(h_1,h_2,…,h_n)$</li>
<li>如果当前 decoder 阶段已经到了$S_{i-1}$，要进行下一个$S_i$​的预测了，接下来计算每一个输入位置$h_j$对当前位置$i$​的影响</li>
</ol>
<p>$$<br>e_{i j}=a\left(s_{i-1}, h_{j}\right)<br>$$</p>
<ol start="3">
<li>$e_{ij}$​做归一化处理，得到 attention 的权重分布</li>
</ol>
<p>$$<br>\alpha_{i j}=\frac{\exp \left(e_{i j}\right)}{\sum_{k=1}^{T_{x}} \exp \left(e_{i k}\right)}<br>$$</p>
<ol start="4">
<li>利用 $α_{ij}$​​ 进行加权求和，得到相应的 context vector</li>
</ol>
<p>$$<br>c_{i}=\sum_{j=1}^{T_{x}} \alpha_{i j} h_{j}<br>$$</p>
<ol start="5">
<li>计算预测最终的输出</li>
</ol>
<p>$$<br>s_{i}=f\left(s_{i-1}, y_{i-1}, c_{i}\right)<br>$$</p>
<h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a><strong>Self-Attention</strong></h3><h4 id="不同于-Attention"><a href="#不同于-Attention" class="headerlink" title="不同于 Attention"></a>不同于 Attention</h4><p>传统的Attention是基于source端和target端的隐变量（hidden state）计算Attention的，得到的结果是源端（source端）的每个词与目标端（target端）每个词之间的依赖关系。</p>
<p>Self -Attention 首先分别在source端和target端进行自身的attention，仅与source input或者target input自身相关的Self -Attention，以捕捉source端或target端自身的词与词之间的依赖关系；然后再把source端的得到的self -Attention加入到target端得到的Attention中，称作为Cross-Attention，以捕捉source端和target端词与词之间的依赖关系。</p>
<p><img src="https://photos.zywvvd.com/vvd-dell-2021-win-10/20210818234646.png" srcset="/img/loading.gif" lazyload></p>
<p>传统的Attention机制<strong>忽略了源端或目标端句子中词与词之间的依赖关系</strong>，相对比，self Attention可以不仅可以得到源端与目标端词与词之间的依赖关系，同时还可以有效获取源端或目标端自身词与词之间的依赖关系。</p>
<h4 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h4><p> 开山的论文 《Attention is all you need》</p>
<details>
<summary>原始论文</summary>
    <iframe src='/js/pdfjs/web/viewer.html?file=https://photos.zywvvd.com/win11-mt/20210814144827.pdf' style='width:100%;height:800px'></iframe>
</details>
#### 计算步骤

<ol>
<li>将输入单词转化成嵌入向量;</li>
<li>根据嵌入向量得到 $ q, k, v $ 三个向量;</li>
<li>为每个向量计算一个score: score $ =q \cdot k $;</li>
<li>为了梯度的稳定, Transformer使用了score归一化，即除以 $ \sqrt{d_{k}} $;</li>
<li>对score施以softmax激活函数;</li>
<li>softmax点乘Value值 $ v $, 得到加权的每个输入向量的评分 $ v $;</li>
<li>相加之后得到最终的输出结果 $ z: \quad z=\sum v 。 $</li>
</ol>
<ul>
<li>核心公式</li>
</ul>
<p>$$<br>Attention  (Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}\right) V<br>$$</p>
<h4 id="图示"><a href="#图示" class="headerlink" title="图示"></a>图示</h4><ul>
<li>Embedding Queries Keys Values</li>
</ul>
<p><img src="https://photos.zywvvd.com/vvd-dell-2021-win-10/20210819231055.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>其中 $Q, K, V$ 是由 $X$ 计算而来的</li>
<li>论文中计算方式如下：</li>
</ul>
<p><img src="https://photos.zywvvd.com/vvd-dell-2021-win-10/20210819231330.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>网络学习参数 $W^Q, Q^K, W^V$，计算得到 $Q, K, V$</li>
<li>由 $Q, K, V$ 计算得到 $Z$</li>
</ul>
<p><img src="https://photos.zywvvd.com/vvd-dell-2021-win-10/20210819235151.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>在Transformer中，同时采用了 resnet 类似的 short-cut 结构</li>
</ul>
<p><img src="https://photos.zywvvd.com/vvd-dell-2021-win-10/20210819235341.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>多头 Attention</li>
</ul>
<p><img src="https://photos.zywvvd.com/vvd-dell-2021-win-10/20210819235509.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>同一组 $X$ 输入多个 Transformer 中，得到多组 $Z_i$，将$Z_i$们连接起来组成大$Z^O$，和 $W^O$ 相乘得到输出层 $Z$</li>
<li>注意 Transformer 中的 Attention 会将 encoder 的 $K$ 和 $V$ 传给 decoder，而 $Q$ 来自与解码器的上一个输出。</li>
</ul>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/gczr/p/14693829.html">https://www.cnblogs.com/gczr/p/14693829.html</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/66076731">https://zhuanlan.zhihu.com/p/66076731</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/46313756">https://zhuanlan.zhihu.com/p/46313756</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/79115586">https://zhuanlan.zhihu.com/p/79115586</a></li>
</ul>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Deep-Learning/">Deep Learning</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Deep-Learning/">Deep Learning</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2021/08/14/hexo/18%20hexo-pdf/hexo-pdf/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Hexo -18- 添加 PDF 阅读功能</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/08/14/python/python-random/python-random-seed/">
                        <span class="hidden-mobile">Python - random 和 numpy.random 线程安全</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"OLRteWxoct1JkWm3Pe9BDYEK-gzGzoHsz","appKey":"YBKiC6SE5hpWUmy0WIyegCrM","placeholder":"遗憾莫过于难忘你的背影，却找不到你来过的痕迹 ...","path":"window.location.pathname","avatar":"retro","meta":["nick","mail","link"],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":true,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false,"requiredFields":[]},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->

  <div class="col-lg-7 mx-auto nopadding-x-md">
    <div class="container custom post-custom mx-auto">
      <img src="https://octodex.github.com/images/jetpacktocat.png" srcset="/img/loading.gif" lazyload class="rounded mx-auto d-block mt-5" style="width:150px; height:150px;">
    </div>
  </div>


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  
  <!-- 备案信息 -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        吉ICP备19007275号-1
      </a>
    </span>
    
      
        <span>
          <a
            href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=22020202000251"
            rel="nofollow noopener"
            class="beian-police"
            target="_blank"
          >
            
              <span style="visibility: hidden; width: 0">|</span>
              <img src="/img/police_beian.png" srcset="/img/loading.gif" lazyload alt="police-icon"/>
            
            <span>22020202000251</span>
          </a>
        </span>
      
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>



  <script  src="/js/local-search.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/z16.model.json"},"display":{"position":"left","width":220,"height":440},"mobile":{"show":false},"react":{"opacity":0.7}});</script></body>
</html>
